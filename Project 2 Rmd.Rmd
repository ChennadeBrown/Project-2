---
title: "Project 2 - Predictive Models"
author: "Alex Prevatte & Chennade Brown"  
date: "10/31/2021"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

```{r, echo = TRUE, message = FALSE}
library(tidyverse)
library(dplyr)
library(knitr)
library(GGally)
library(corrplot)
library(caret)
library(randomForest)
```

## Data
```{r, echo = TRUE, message = FALSE}
# Import the Data.
 onlineNews <- read_csv("OnlineNewsPopularity.csv")
```

```{r, echo = TRUE}

# Start with using data from a single data_channel_is_* source
variable.names(onlineNews)

# filtered rows for data_channel_is_lifestyle and removed other 5 categories
# removed non-predictive variables
onlineNewsLifestyle <- onlineNews %>% filter(`data_channel_is_lifestyle` ==  1) %>% 
  select(- c(`data_channel_is_bus`, `data_channel_is_entertainment`,
             `data_channel_is_socmed`, `data_channel_is_tech`,
             `data_channel_is_world`, url, `timedelta`))

# Remove space in front of each column name
names(onlineNewsLifestyle) <- sub(" ", "", names(onlineNewsLifestyle))

# Convert to dataframe for plotting
onlineNewsLifestyle <- data.frame(onlineNewsLifestyle)

```

## Summarizations
```{r, echo = TRUE}
# Summary statistics for shares
sum <- summary(onlineNewsLifestyle$shares)
std <- sd(onlineNewsLifestyle$shares)
median <- sum[3]
median
```

```{r}
# Create Day variable to combine days for contingency table
dayShares <- onlineNewsLifestyle %>% 
  mutate(Day = if_else(weekday_is_monday == 1, "M",
                          if_else(weekday_is_tuesday == 1, "T",
                                  if_else(weekday_is_wednesday == 1, "W", 
                                          if_else(weekday_is_thursday == 1, "R",
                                                  if_else(weekday_is_friday == 1, "F",
                                          "Weekend"))))))

# Add Popular variable for rows where shares is greater than the median
dayShares <- dayShares %>% mutate(Popular = ifelse(shares > median, "Yes", "No")) %>% select(Popular, everything())

# Contingency table for day of the week and shares greater than the median
table(dayShares$Popular, factor(dayShares$Day, levels = c("M", "T", "W", 
                                                          "R", "F", "Weekend")))

```

```{r, echo = TRUE}
# Scatterplot of Number of words in title vs. shares
ggplot(onlineNewsLifestyle, aes(n_tokens_title, shares)) +
  geom_point()

# Scatterplot of Number of words in content vs. shares
ggplot(onlineNewsLifestyle, aes(n_tokens_content, shares)) +
  geom_point()

# Histogram of total shares. Median line drawn in
ggplot(onlineNewsLifestyle, aes(x=shares))+
  geom_histogram(binwidth = 500, color="darkblue", fill="lightblue") +
  xlim(0,30000) +
  geom_vline(aes(xintercept = median), colour="black")
```

```{r, echo = TRUE}
# Summary statistics for the number of words in the content.
sumWords <- summary(onlineNewsLifestyle$n_tokens_content)
sumWords
```

```{r, echo = TRUE}
# Summary statistics for the number of links in the content. 
sumLinks <- summary(onlineNewsLifestyle$num_hrefs)
sumLinks
```

```{r, echo = TRUE}
# Summary statistics for the number of images in the content.
sumImages <- summary(onlineNewsLifestyle$num_imgs)
sumImages
```

```{r, echo = TRUE}
# Add Word variable for words to include low, average, and high word count and combine with dayshares dataframe for contingency table.
wordLinkShares <- dayShares %>% mutate(Words = if_else(n_tokens_content <= 500, "Low", if_else(n_tokens_content <= 625, "Average", "High")))

```

```{r, echo = TRUE}
# Add Link variable for the number of links in the content to include low, average, and high count.
wordLinkShares <- wordLinkShares %>% mutate(Links = if_else(num_hrefs <= 9, "Low", if_else(num_hrefs <= 14, "Average","High")))

# Remove extra columns added to onLineNewsLifestyle.
onlineNewsLifestyle$WordCount <- NULL
onlineNewsLifestyle$Popular <- NULL
onlineNewsLifestyle$Words <- NULL
onlineNewsLifestyle$Links <- NULL
onlineNewsLifestyle$Day <- NULL
```

```{r, echo = TRUE}
# Contingency table for the number of words in the content based on grouping the word count into categories of low, average, and high word count and grouping the shares based on popularity (shares greater than the median).
table(wordLinkShares$Popular, wordLinkShares$Words)
```

```{r, echo = TRUE}
# Contingency table for the number of links in the content based on grouping the link count into categories of low, average,and high and shares based on popularity (shares greater than the median)
table(wordLinkShares$Popular, wordLinkShares$Links)
```

```{r, echo = TRUE, message = FALSE}
# Select predictors to view in GGPairs plot.
xpred <- onlineNewsLifestyle %>% select(n_tokens_content, n_tokens_title, num_keywords, rate_positive_words, rate_negative_words, shares)

xpred2 <- onlineNewsLifestyle %>% select(num_hrefs, global_subjectivity, num_imgs, title_subjectivity, max_positive_polarity, shares)

# GGPairs plot to view correlation among the predictors.  Correlation greater than 75% indicates the predictors are highly correlated.
ggpairs(xpred, title = "Correlogram with ggpairs")
ggpairs(xpred2, title = "Correlogram with ggpairs")
```

```{r, echo = TRUE}
# The following scatterplot shows the trend of shares as a function of the number of links in the content.  An upward trend in the points indicates that articles with more links are shared more often.  A downward trend would indicate that articles with more links are shared less often.  If there is neither an upward or downward trend this indicates that the number of links in the article has no effect on whether the article will be shared.
correlation <- cor(onlineNewsLifestyle$shares, onlineNewsLifestyle$num_hrefs)  
g <- ggplot(onlineNewsLifestyle, aes(x = num_hrefs, y = shares)) + labs(y ="Number of Shares", x = "Number of Links")
g + geom_point(col = "red") + ggtitle("Number of Links vs. Shares") + geom_text(x = 125, y = 30000, size = 5, label = paste0("Correlation = ", round(correlation, 2)))

```

```{r, echo = TRUE}
# The following scatterplot shows the relationship between the rate of positive words in the articles and the number of shares.  If the plots are on an upward trajectory then articles with more positive words are shared the most.  If the plots are on a downward trend then the articles with the most positive words are shared the least.
correlationTwo <- cor(onlineNewsLifestyle$shares, onlineNewsLifestyle$rate_positive_words)  
g <- ggplot(onlineNewsLifestyle, aes(x = rate_positive_words, y = shares)) + labs(y ="Number of Shares", x = "Rate of Positive Words")
g + geom_point(col = "red") + ggtitle("Rate of Positive Words vs. Shares") + geom_text(x = 0.75, y = 100000, size = 5, label = paste0("Correlation = ", round(correlationTwo, 2)))

```

## Modeling
```{r, echo = TRUE}
# Split the data into a training (70% of the data) and test set (30% of the data).
set.seed(90)
trainIndex <- createDataPartition(onlineNewsLifestyle$shares, p = 0.7, list = FALSE)
onlineNewsTrain <- onlineNewsLifestyle[trainIndex, ]
onlineNewsTest <- onlineNewsLifestyle[-trainIndex, ]
dim(onlineNewsTrain)
dim(onlineNewsTest)
```

### Linear Regression Models
A linear regression model is a model used to determine the relationship between two or more variables by fitting a linear equation to the data.  The linear equation is in the form of: Y = Bo + B1X + E where Y is the response variable, X is the explanatory variable, Bo is the y intercept, and B1 is the slope.  The model can be used to predict the value of the response variable based on the values of the explanatory variables.  For example a linear regression model can be used to model the relationship between years of experience and salary.

```{r, echo = TRUE}
# Store model one in a formula.
modelOne <- as.formula("shares ~ n_tokens_content + n_tokens_title + rate_positive_words + num_keywords + global_subjectivity + max_positive_polarity + num_imgs")

# Fit the linear regression models.
fit1 <- train(modelOne, data = onlineNewsTrain,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10))
fit1
```

### Random Forest Model
Random Forest models are an extension of the tree based method bagging.  The random forest algorithm creates multiple trees from bootstrapped samples, averages those results, and uses a random subset of predictors for each bootstrap sample/tree fit.  Random forests can be used for classification and regression problems.

```{r, echo = TRUE}
rfFit <- train(shares ~., data = onlineNewsTrain, 
               method = "rf", 
               trainControl = trainControl(method = "cv",
                                           number = 5),
               tuneGrid = data.frame(mtry = 1:8))
rfFit
```

## Comparison

```{r, echo = TRUE}
# Compare linear regression model fit1 on the test set.
pred <- predict(fit1, newdata = onlineNewsTest)
postResample(pred, obs = onlineNewsTest$shares)

# Compare random forest model rfFit on the test set.
predForest <- predict(rfFit, newdata = onlineNewsTest)
postResample(predForest, onlineNewsTest$shares)
```

## Automation



